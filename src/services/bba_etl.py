from src.config import RAW_DIR, PROCESSED_DIR
from src.core.cleaner import GenericCleaner


def run_bba_sales_etl():
    print("ğŸš€ [Service] Starting BBA Sales Data Pipeline...")

    input_file = RAW_DIR / "dirty_real_sales.csv"
    output_file = PROCESSED_DIR / "clean_bba_sales.csv"

    # 1. å®ä¾‹åŒ–é€šç”¨æ¸…æ´—å™¨
    cleaner = GenericCleaner()

    # 2. å®šä¹‰ BBA é¡¹ç›®ç‰¹æœ‰çš„æ¸…æ´—é€»è¾‘ (ç»„è£…æµæ°´çº¿)
    (
        cleaner.load_file(input_file)
        # æ­¥éª¤ A: æŠŠ "Product Line" è¿™ç§åˆ—åæ´—æˆ "product_line"
        .normalize_headers()
        # æ­¥éª¤ B: å¤„ç†åœ°åŒºå’Œäººåçš„æ ¼å¼ (North, John Doe)
        .clean_text_columns(
            columns=["region", "salesperson", "county"], case_type="title"
        )
        # æ­¥éª¤ C: å¤„ç†é‡‘é¢ "$100" -> 100.0
        .extract_numbers(columns=["sales", "calls"])
        # æ­¥éª¤ D: å¡«å…… sales çš„ç©ºå€¼ä¸ºå¹³å‡å€¼ï¼Œä½†åˆ é™¤ calls ä¸ºç©ºçš„è¡Œ
        .handle_missing_values(columns=["sales"], strategy="mean")
        .handle_missing_values(columns=["calls"], strategy="drop")
        # æ­¥éª¤ E: å»é‡å¹¶ä¿å­˜
        .drop_duplicates()
        .save(output_file)
    )


if __name__ == "__main__":
    run_bba_sales_etl()
